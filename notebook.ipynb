{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sounds Like\n",
    "Find a song that sounds like something you would love to listen to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "\n",
    "# %pip install torch\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# from torch import nn, optim\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from utils.converter import h5_to_dict\n",
    "from pathlib import Path\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the data directory\n",
    "Path.mkdir(Path(\"data\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CSV_PATH = \"data/songs.csv\"\n",
    "INPUT_FILE_PATH = \"data/MillionSongSubset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download resources\n",
    "\n",
    "You will need to download all of these resources before you can continue. Altogether, you will need at most 4 GB of storage available. If you prefer not doing it yourself, the next cell after this will automatically download and extract everything. However, it will take noticeably longer to uncompress the data.\n",
    "\n",
    "1. [Million Song Subset](http://labrosa.ee.columbia.edu/~dpwe/tmp/millionsongsubset.tar.gz\")\n",
    "2. [Sample Track](http://millionsongdataset.com/sites/default/files/AdditionalFiles/TRAXLZU12903D05F94.h5)\n",
    "3. [Taste Profile](http://labrosa.ee.columbia.edu/~dpwe/tmp/train_triplets.txt.zip)\n",
    "4. [Mismatched tracks](http://millionsongdataset.com/sites/default/files/tasteprofile/sid_mismatches.txt)\n",
    "\n",
    "Running the cell below will **override any existing resources in the data folder**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOURCES = [\n",
    "    \"http://millionsongdataset.com/sites/default/files/tasteprofile/sid_mismatches.txt\",\n",
    "    \"http://labrosa.ee.columbia.edu/~dpwe/tmp/train_triplets.txt.zip\",\n",
    "    \"http://labrosa.ee.columbia.edu/~dpwe/tmp/millionsongsubset.tar.gz\",\n",
    "    \"http://millionsongdataset.com/sites/default/files/AdditionalFiles/TRAXLZU12903D05F94.h5\",\n",
    "    \"http://millionsongdataset.com/sites/default/files/thisismyjam/jam_to_msd.tsv\",\n",
    "    \"https://archive.org/download/thisismyjam-datadump/thisismyjam-datadump.zip\"\n",
    "]\n",
    "\n",
    "files_downloaded = 0\n",
    "\n",
    "for resource in RESOURCES:\n",
    "    # Download all resources\n",
    "    local_filename = resource[resource.rindex(\"/\") + 1:]\n",
    "\n",
    "    try:\n",
    "        with requests.get(resource, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "\n",
    "            with open(f\"data/{local_filename}\", \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        \n",
    "        files_downloaded += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download resource - {resource}.\\nError: {e}\\nDO NOT PROCEED TO THE NEXT CELL.\")\n",
    "        break\n",
    "\n",
    "print(f\"{files_downloaded} of {len(RESOURCES)} resources(s) downloaded\")\n",
    "\n",
    "if files_downloaded == len(RESOURCES):\n",
    "    # Extract compressed resources\n",
    "    with tarfile.open(\"data/millionsongsubset.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall(\"data/\")\n",
    "    with zipfile.ZipFile(\"data/train_triplets.txt.zip\", \"r\") as zip:\n",
    "        zip.extractall(\"data/\")\n",
    "    with zipfile.ZipFile(\"data/thisismyjam-datadump.zip\", \"r\") as zip:\n",
    "        zip.extractall(\"data/\")\n",
    "    \n",
    "    # Delete the zip files\n",
    "    os.remove(\"data/millionsongsubset.tar.gz\")\n",
    "    os.remove(\"data/train_triplets.txt.zip\")\n",
    "    os.remove(\"data/thisismyjam-datadump.zip\")\n",
    "    \n",
    "    print(\"Done. All data uncompressed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "If you already have the song dataset ready as a pandas dataframe, then you can skip Cell 4 and start executing from Cell 5 to import your data. If you do not have a pandas dataframe containing your songs yet, you must run Cell 4 if you need to convert the HDF5 files in the MillionSong dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN !!ONLY!! THIS (AND NOT THE CELL BELOW) IF songs.csv DOES NOT EXIST in your data/ folder\n",
    "# This will take approximately 10 minutes for 10,000 records.\n",
    "rows = []\n",
    "\n",
    "for root, _, files in os.walk(INPUT_FILE_PATH):\n",
    "\tfor file in files:\n",
    "\t\th5_path = os.path.join(root, file)\n",
    "\t\ttry:\n",
    "\t\t\tsong_data = h5_to_dict(h5_path)\n",
    "\t\t\trows.append(song_data)\n",
    "\t\texcept Exception as e :\n",
    "\t\t\tprint(f\"Error loading file {file}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(OUTPUT_CSV_PATH , index=False)\n",
    "\n",
    "print(f\"CSV created: {OUTPUT_CSV_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>analysis/bars_confidence</th>\n",
       "      <th>analysis/bars_start</th>\n",
       "      <th>analysis/beats_confidence</th>\n",
       "      <th>analysis/beats_start</th>\n",
       "      <th>analysis/sections_confidence</th>\n",
       "      <th>analysis/sections_start</th>\n",
       "      <th>analysis/segments_confidence</th>\n",
       "      <th>analysis/segments_loudness_max</th>\n",
       "      <th>analysis/segments_loudness_max_time</th>\n",
       "      <th>analysis/segments_loudness_start</th>\n",
       "      <th>...</th>\n",
       "      <th>metadata/songs/artist_id</th>\n",
       "      <th>metadata/songs/artist_latitude</th>\n",
       "      <th>metadata/songs/artist_location</th>\n",
       "      <th>metadata/songs/artist_longitude</th>\n",
       "      <th>metadata/songs/artist_mbid</th>\n",
       "      <th>metadata/songs/artist_name</th>\n",
       "      <th>musicbrainz/artist_mbtags</th>\n",
       "      <th>musicbrainz/artist_mbtags_count</th>\n",
       "      <th>musicbrainz/songs/idx_artist_mbtags</th>\n",
       "      <th>musicbrainz/songs/year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.643 0.746 0.722 0.095 0.091 0.362 0.465 0.2...</td>\n",
       "      <td>[  0.58521   2.94247   5.14371   7.74554  10.3...</td>\n",
       "      <td>[0.834 0.851 0.65  0.635 0.532 0.753 0.622 0.6...</td>\n",
       "      <td>[  0.58521   1.19196   1.78893   2.37813   2.9...</td>\n",
       "      <td>[1.    1.    0.218 0.133 0.384 0.326 0.373 0.1...</td>\n",
       "      <td>[  0.        7.74554  36.44331  43.61667  75.1...</td>\n",
       "      <td>[0.    1.    0.483 0.137 0.42  1.    0.257 1. ...</td>\n",
       "      <td>[-60.    -31.646 -34.565 -38.407 -34.696 -20.5...</td>\n",
       "      <td>[0.      0.10929 0.11044 0.0844  0.05898 0.073...</td>\n",
       "      <td>[-60.    -60.    -40.84  -40.401 -38.456 -39.6...</td>\n",
       "      <td>...</td>\n",
       "      <td>ARD7TVE1187B99BFB1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>California - LA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e77e51a5-4761-45b3-9847-2051f811e366</td>\n",
       "      <td>Casual</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.007 0.259 0.172 0.404 0.011 0.016 0.035 0.0...</td>\n",
       "      <td>[  0.71054   2.71502   4.70861   6.69288   8.6...</td>\n",
       "      <td>[1.    0.945 0.714 0.973 0.818 0.974 0.878 0.6...</td>\n",
       "      <td>[  0.20627   0.71054   1.21836   1.71841   2.2...</td>\n",
       "      <td>[1.    0.451 0.27  0.397 0.225 0.426 0.459 0.1...</td>\n",
       "      <td>[  0.        8.1777   19.52952  38.84063  50.2...</td>\n",
       "      <td>[0.    1.    0.93  0.643 0.761 0.21  1.    0.7...</td>\n",
       "      <td>[-60.    -14.269 -10.165 -18.098 -19.136 -18.9...</td>\n",
       "      <td>[0.      0.05811 0.03982 0.04186 0.03568 0.033...</td>\n",
       "      <td>[-60.    -60.    -23.521 -25.16  -27.133 -24.2...</td>\n",
       "      <td>...</td>\n",
       "      <td>ARMJAGH1187FB546F3</td>\n",
       "      <td>35.14968</td>\n",
       "      <td>Memphis, TN</td>\n",
       "      <td>-90.04892</td>\n",
       "      <td>1c78ab62-db33-4433-8d0b-7c8dcf1849c2</td>\n",
       "      <td>The Box Tops</td>\n",
       "      <td>[b'classic pop and rock']</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.98  0.399 0.185 0.27  0.422 0.    0.445 0.6...</td>\n",
       "      <td>[  0.73152   1.39732   2.04852   2.68691   3.3...</td>\n",
       "      <td>[0.98  0.399 0.185 0.27  0.422 0.    0.445 0.6...</td>\n",
       "      <td>[  0.73152   1.39732   2.04852   2.68691   3.3...</td>\n",
       "      <td>[1.    0.121 0.214 0.198 0.66  0.468 0.591 0.363]</td>\n",
       "      <td>[  0.       37.88678  49.43939  68.63657  98.8...</td>\n",
       "      <td>[0.    1.    0.106 0.048 0.282 0.69  0.308 0.4...</td>\n",
       "      <td>[-59.895 -11.914 -10.344  -9.678  -9.22   -8.3...</td>\n",
       "      <td>[0.27572 0.1589  0.0515  0.0741  0.09185 0.044...</td>\n",
       "      <td>[-60.    -59.9   -12.744 -12.003 -12.991 -15.9...</td>\n",
       "      <td>...</td>\n",
       "      <td>ARKRRTF1187B9984DA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7a273984-edd9-4451-9c4d-39b38f05ebcd</td>\n",
       "      <td>Sonora Santanera</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.017 0.05  0.014 0.008 0.114 0.019 0.083 0.0...</td>\n",
       "      <td>[  1.30621   3.29887   5.30252   7.32327   9.3...</td>\n",
       "      <td>[0.809 0.616 0.789 0.66  0.439 0.758 0.604 0.7...</td>\n",
       "      <td>[  0.81002   1.30621   1.80617   2.2996    2.8...</td>\n",
       "      <td>[1.    0.086 0.153 0.146 0.088 0.217 0.372 0.1...</td>\n",
       "      <td>[  0.       20.38681  27.94943  55.12454  67.7...</td>\n",
       "      <td>[1.    1.    0.919 0.591 0.841 0.174 0.753 0.5...</td>\n",
       "      <td>[-18.682  -9.55   -9.709  -8.633  -7.434 -11.7...</td>\n",
       "      <td>[0.34385 0.07741 0.04658 0.07981 0.04477 0.069...</td>\n",
       "      <td>[-60.    -27.665 -21.241 -15.222 -18.915 -15.0...</td>\n",
       "      <td>...</td>\n",
       "      <td>AR7G5I41187FB4CE6C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>London, England</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e188a520-9cb7-4f73-a3d7-2f70c6538e92</td>\n",
       "      <td>Adam Ant</td>\n",
       "      <td>[b'uk' b'british' b'english']</td>\n",
       "      <td>[1 1 1]</td>\n",
       "      <td>0</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.175 0.409 0.639 0.067 0.016 0.066 0.002 0.3...</td>\n",
       "      <td>[  1.06368   2.91491   4.76729   6.61852   8.4...</td>\n",
       "      <td>[0.883 0.738 0.484 0.609 0.625 0.719 0.484 0.5...</td>\n",
       "      <td>[1.3576000e-01 5.9914000e-01 1.0636800e+00 1.5...</td>\n",
       "      <td>[1.    0.768 0.611 0.388 0.52  0.42  0.499 0.3...</td>\n",
       "      <td>[  0.        8.00636  23.26694  67.22425  74.1...</td>\n",
       "      <td>[0.    1.    0.359 1.    0.963 0.544 1.    0.7...</td>\n",
       "      <td>[-59.813  -7.713 -16.13   -2.512  -8.088  -8.7...</td>\n",
       "      <td>[0.06094 0.06433 0.02255 0.02018 0.02463 0.016...</td>\n",
       "      <td>[-60.    -59.828 -19.551 -32.609 -21.899 -20.1...</td>\n",
       "      <td>...</td>\n",
       "      <td>ARXR32B1187FB57099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c6903a2e-063c-4f91-a284-17b8f421be7b</td>\n",
       "      <td>Gob</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.121 0.511 0.356 0.397 0.193 0.262 0.361 0.3...</td>\n",
       "      <td>[  1.17118   2.44699   3.76552   5.07403   6.3...</td>\n",
       "      <td>[0.438 0.164 0.143 0.044 0.047 0.22  0.279 0.2...</td>\n",
       "      <td>[  0.74856   1.17118   1.59278   2.0154    2.4...</td>\n",
       "      <td>[1.    1.    0.041 0.279 0.53  0.864 0.367 0.5...</td>\n",
       "      <td>[  0.        6.82464  46.38231  69.10539  85.0...</td>\n",
       "      <td>[0.    0.292 0.667 0.274 0.332 0.131 0.077 0.2...</td>\n",
       "      <td>[-58.879 -54.379 -46.634 -45.289 -43.067 -42.4...</td>\n",
       "      <td>[0.43155 0.15939 0.13164 0.08969 0.11711 0.044...</td>\n",
       "      <td>[-60.    -58.929 -54.569 -48.97  -46.964 -45.4...</td>\n",
       "      <td>...</td>\n",
       "      <td>ARKFYS91187B98E58F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79c403f9-5467-4f23-8426-9ca3fc60a115</td>\n",
       "      <td>Jeff And Sheri Easter</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.709 0.641 0.531 0.542 0.47  0.049 0.573 0.2...</td>\n",
       "      <td>[  0.27253   0.70535   1.13191   1.53913   1.9...</td>\n",
       "      <td>[0.709 0.641 0.531 0.542 0.47  0.049 0.573 0.2...</td>\n",
       "      <td>[  0.27253   0.70535   1.13191   1.53913   1.9...</td>\n",
       "      <td>[1.    0.338 0.477 0.862]</td>\n",
       "      <td>[ 0.      10.6519  54.27073 93.68212]</td>\n",
       "      <td>[0.    1.    1.    1.    0.285 1.    0.034 0.7...</td>\n",
       "      <td>[-55.508 -10.928 -27.764 -14.137 -14.675 -14.6...</td>\n",
       "      <td>[0.07564 0.05985 0.03653 0.07117 0.07724 0.077...</td>\n",
       "      <td>[-60.    -55.786 -55.547 -45.022 -19.357 -32.7...</td>\n",
       "      <td>...</td>\n",
       "      <td>ARD0S291187B9B7BF5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56503d6d-094e-4c28-ae3d-04cc748ade5b</td>\n",
       "      <td>Rated R</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.142 0.2   0.358 0.321 0.017 0.138 0.124 0.2...</td>\n",
       "      <td>[  0.65428   2.42697   4.21143   5.98706   7.7...</td>\n",
       "      <td>[0.234 0.31  0.217 0.026 0.018 0.02  0.176 0.2...</td>\n",
       "      <td>[  0.65428   1.24174   1.83362   2.42697   3.0...</td>\n",
       "      <td>[1.    0.749 0.416 0.667 0.055 0.661 0.298 0.2...</td>\n",
       "      <td>[  0.       15.99351  40.50153  57.1495   72.0...</td>\n",
       "      <td>[0.    0.011 0.427 0.77  0.233 1.    0.03  0.7...</td>\n",
       "      <td>[-59.479 -57.932 -52.588 -43.102 -41.532  -8.0...</td>\n",
       "      <td>[0.30442 0.08504 0.44208 0.21509 0.0159  0.192...</td>\n",
       "      <td>[-60.    -59.5   -57.988 -52.612 -43.199 -53.1...</td>\n",
       "      <td>...</td>\n",
       "      <td>AR10USD1187B99F3F1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burlington, Ontario, Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d89de379-665d-425c-b2e9-41b95d1edb36</td>\n",
       "      <td>Tweeterfriendly Music</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.806 0.384 0.868 0.601 0.509 0.753 0.35  0.1...</td>\n",
       "      <td>[  1.91886   4.69392   7.46235  10.22307  12.9...</td>\n",
       "      <td>[0.44  0.    0.253 0.418 0.227 0.    0.107 0. ...</td>\n",
       "      <td>[  1.22595   1.91886   2.6098    3.30422   3.9...</td>\n",
       "      <td>[1.    0.946 0.222 0.558 0.062 0.126 0.026 0.0...</td>\n",
       "      <td>[  0.        8.84703  45.16366 100.4712  119.3...</td>\n",
       "      <td>[0.    0.135 0.252 0.215 0.015 0.245 0.072 0.3...</td>\n",
       "      <td>[-56.079 -55.018 -53.516 -52.784 -52.486 -50.7...</td>\n",
       "      <td>[1.22157 0.05528 0.24208 0.06153 0.07085 0.125...</td>\n",
       "      <td>[-60.    -57.277 -56.676 -55.359 -53.96  -54.5...</td>\n",
       "      <td>...</td>\n",
       "      <td>AR8ZCNI1187B9A069B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19d232b9-b4d7-4dc8-b259-bf65efb655b1</td>\n",
       "      <td>Planet P Project</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.047 0.007 0.615 0.741 0.454 0.124 0.376 0.3...</td>\n",
       "      <td>[  0.62445   2.73661   4.83785   6.94481   9.0...</td>\n",
       "      <td>[1.    1.    1.    0.944 1.    1.    0.947 1. ...</td>\n",
       "      <td>[9.9330000e-02 6.2445000e-01 1.1542300e+00 1.6...</td>\n",
       "      <td>[1.    0.591 0.475 0.857 0.717 0.714 0.664 0.6...</td>\n",
       "      <td>[  0.       19.57644  60.10462  77.47084  95.3...</td>\n",
       "      <td>[0.    1.    0.783 ... 1.    0.43  0.052]</td>\n",
       "      <td>[-60.     -7.309 -17.716 ... -16.902 -17.35  -...</td>\n",
       "      <td>[0.      0.02321 0.02379 ... 0.04617 0.02703 0...</td>\n",
       "      <td>[-60.    -60.    -29.164 ... -36.785 -21.096 -...</td>\n",
       "      <td>...</td>\n",
       "      <td>ARNTLGG11E2835DDB9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4d96f7d0-2f0e-4e92-ba70-a405f96f8cec</td>\n",
       "      <td>Clp</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            analysis/bars_confidence  \\\n",
       "0  [0.643 0.746 0.722 0.095 0.091 0.362 0.465 0.2...   \n",
       "1  [0.007 0.259 0.172 0.404 0.011 0.016 0.035 0.0...   \n",
       "2  [0.98  0.399 0.185 0.27  0.422 0.    0.445 0.6...   \n",
       "3  [0.017 0.05  0.014 0.008 0.114 0.019 0.083 0.0...   \n",
       "4  [0.175 0.409 0.639 0.067 0.016 0.066 0.002 0.3...   \n",
       "5  [0.121 0.511 0.356 0.397 0.193 0.262 0.361 0.3...   \n",
       "6  [0.709 0.641 0.531 0.542 0.47  0.049 0.573 0.2...   \n",
       "7  [0.142 0.2   0.358 0.321 0.017 0.138 0.124 0.2...   \n",
       "8  [0.806 0.384 0.868 0.601 0.509 0.753 0.35  0.1...   \n",
       "9  [0.047 0.007 0.615 0.741 0.454 0.124 0.376 0.3...   \n",
       "\n",
       "                                 analysis/bars_start  \\\n",
       "0  [  0.58521   2.94247   5.14371   7.74554  10.3...   \n",
       "1  [  0.71054   2.71502   4.70861   6.69288   8.6...   \n",
       "2  [  0.73152   1.39732   2.04852   2.68691   3.3...   \n",
       "3  [  1.30621   3.29887   5.30252   7.32327   9.3...   \n",
       "4  [  1.06368   2.91491   4.76729   6.61852   8.4...   \n",
       "5  [  1.17118   2.44699   3.76552   5.07403   6.3...   \n",
       "6  [  0.27253   0.70535   1.13191   1.53913   1.9...   \n",
       "7  [  0.65428   2.42697   4.21143   5.98706   7.7...   \n",
       "8  [  1.91886   4.69392   7.46235  10.22307  12.9...   \n",
       "9  [  0.62445   2.73661   4.83785   6.94481   9.0...   \n",
       "\n",
       "                           analysis/beats_confidence  \\\n",
       "0  [0.834 0.851 0.65  0.635 0.532 0.753 0.622 0.6...   \n",
       "1  [1.    0.945 0.714 0.973 0.818 0.974 0.878 0.6...   \n",
       "2  [0.98  0.399 0.185 0.27  0.422 0.    0.445 0.6...   \n",
       "3  [0.809 0.616 0.789 0.66  0.439 0.758 0.604 0.7...   \n",
       "4  [0.883 0.738 0.484 0.609 0.625 0.719 0.484 0.5...   \n",
       "5  [0.438 0.164 0.143 0.044 0.047 0.22  0.279 0.2...   \n",
       "6  [0.709 0.641 0.531 0.542 0.47  0.049 0.573 0.2...   \n",
       "7  [0.234 0.31  0.217 0.026 0.018 0.02  0.176 0.2...   \n",
       "8  [0.44  0.    0.253 0.418 0.227 0.    0.107 0. ...   \n",
       "9  [1.    1.    1.    0.944 1.    1.    0.947 1. ...   \n",
       "\n",
       "                                analysis/beats_start  \\\n",
       "0  [  0.58521   1.19196   1.78893   2.37813   2.9...   \n",
       "1  [  0.20627   0.71054   1.21836   1.71841   2.2...   \n",
       "2  [  0.73152   1.39732   2.04852   2.68691   3.3...   \n",
       "3  [  0.81002   1.30621   1.80617   2.2996    2.8...   \n",
       "4  [1.3576000e-01 5.9914000e-01 1.0636800e+00 1.5...   \n",
       "5  [  0.74856   1.17118   1.59278   2.0154    2.4...   \n",
       "6  [  0.27253   0.70535   1.13191   1.53913   1.9...   \n",
       "7  [  0.65428   1.24174   1.83362   2.42697   3.0...   \n",
       "8  [  1.22595   1.91886   2.6098    3.30422   3.9...   \n",
       "9  [9.9330000e-02 6.2445000e-01 1.1542300e+00 1.6...   \n",
       "\n",
       "                        analysis/sections_confidence  \\\n",
       "0  [1.    1.    0.218 0.133 0.384 0.326 0.373 0.1...   \n",
       "1  [1.    0.451 0.27  0.397 0.225 0.426 0.459 0.1...   \n",
       "2  [1.    0.121 0.214 0.198 0.66  0.468 0.591 0.363]   \n",
       "3  [1.    0.086 0.153 0.146 0.088 0.217 0.372 0.1...   \n",
       "4  [1.    0.768 0.611 0.388 0.52  0.42  0.499 0.3...   \n",
       "5  [1.    1.    0.041 0.279 0.53  0.864 0.367 0.5...   \n",
       "6                          [1.    0.338 0.477 0.862]   \n",
       "7  [1.    0.749 0.416 0.667 0.055 0.661 0.298 0.2...   \n",
       "8  [1.    0.946 0.222 0.558 0.062 0.126 0.026 0.0...   \n",
       "9  [1.    0.591 0.475 0.857 0.717 0.714 0.664 0.6...   \n",
       "\n",
       "                             analysis/sections_start  \\\n",
       "0  [  0.        7.74554  36.44331  43.61667  75.1...   \n",
       "1  [  0.        8.1777   19.52952  38.84063  50.2...   \n",
       "2  [  0.       37.88678  49.43939  68.63657  98.8...   \n",
       "3  [  0.       20.38681  27.94943  55.12454  67.7...   \n",
       "4  [  0.        8.00636  23.26694  67.22425  74.1...   \n",
       "5  [  0.        6.82464  46.38231  69.10539  85.0...   \n",
       "6              [ 0.      10.6519  54.27073 93.68212]   \n",
       "7  [  0.       15.99351  40.50153  57.1495   72.0...   \n",
       "8  [  0.        8.84703  45.16366 100.4712  119.3...   \n",
       "9  [  0.       19.57644  60.10462  77.47084  95.3...   \n",
       "\n",
       "                        analysis/segments_confidence  \\\n",
       "0  [0.    1.    0.483 0.137 0.42  1.    0.257 1. ...   \n",
       "1  [0.    1.    0.93  0.643 0.761 0.21  1.    0.7...   \n",
       "2  [0.    1.    0.106 0.048 0.282 0.69  0.308 0.4...   \n",
       "3  [1.    1.    0.919 0.591 0.841 0.174 0.753 0.5...   \n",
       "4  [0.    1.    0.359 1.    0.963 0.544 1.    0.7...   \n",
       "5  [0.    0.292 0.667 0.274 0.332 0.131 0.077 0.2...   \n",
       "6  [0.    1.    1.    1.    0.285 1.    0.034 0.7...   \n",
       "7  [0.    0.011 0.427 0.77  0.233 1.    0.03  0.7...   \n",
       "8  [0.    0.135 0.252 0.215 0.015 0.245 0.072 0.3...   \n",
       "9          [0.    1.    0.783 ... 1.    0.43  0.052]   \n",
       "\n",
       "                      analysis/segments_loudness_max  \\\n",
       "0  [-60.    -31.646 -34.565 -38.407 -34.696 -20.5...   \n",
       "1  [-60.    -14.269 -10.165 -18.098 -19.136 -18.9...   \n",
       "2  [-59.895 -11.914 -10.344  -9.678  -9.22   -8.3...   \n",
       "3  [-18.682  -9.55   -9.709  -8.633  -7.434 -11.7...   \n",
       "4  [-59.813  -7.713 -16.13   -2.512  -8.088  -8.7...   \n",
       "5  [-58.879 -54.379 -46.634 -45.289 -43.067 -42.4...   \n",
       "6  [-55.508 -10.928 -27.764 -14.137 -14.675 -14.6...   \n",
       "7  [-59.479 -57.932 -52.588 -43.102 -41.532  -8.0...   \n",
       "8  [-56.079 -55.018 -53.516 -52.784 -52.486 -50.7...   \n",
       "9  [-60.     -7.309 -17.716 ... -16.902 -17.35  -...   \n",
       "\n",
       "                 analysis/segments_loudness_max_time  \\\n",
       "0  [0.      0.10929 0.11044 0.0844  0.05898 0.073...   \n",
       "1  [0.      0.05811 0.03982 0.04186 0.03568 0.033...   \n",
       "2  [0.27572 0.1589  0.0515  0.0741  0.09185 0.044...   \n",
       "3  [0.34385 0.07741 0.04658 0.07981 0.04477 0.069...   \n",
       "4  [0.06094 0.06433 0.02255 0.02018 0.02463 0.016...   \n",
       "5  [0.43155 0.15939 0.13164 0.08969 0.11711 0.044...   \n",
       "6  [0.07564 0.05985 0.03653 0.07117 0.07724 0.077...   \n",
       "7  [0.30442 0.08504 0.44208 0.21509 0.0159  0.192...   \n",
       "8  [1.22157 0.05528 0.24208 0.06153 0.07085 0.125...   \n",
       "9  [0.      0.02321 0.02379 ... 0.04617 0.02703 0...   \n",
       "\n",
       "                    analysis/segments_loudness_start  ...  \\\n",
       "0  [-60.    -60.    -40.84  -40.401 -38.456 -39.6...  ...   \n",
       "1  [-60.    -60.    -23.521 -25.16  -27.133 -24.2...  ...   \n",
       "2  [-60.    -59.9   -12.744 -12.003 -12.991 -15.9...  ...   \n",
       "3  [-60.    -27.665 -21.241 -15.222 -18.915 -15.0...  ...   \n",
       "4  [-60.    -59.828 -19.551 -32.609 -21.899 -20.1...  ...   \n",
       "5  [-60.    -58.929 -54.569 -48.97  -46.964 -45.4...  ...   \n",
       "6  [-60.    -55.786 -55.547 -45.022 -19.357 -32.7...  ...   \n",
       "7  [-60.    -59.5   -57.988 -52.612 -43.199 -53.1...  ...   \n",
       "8  [-60.    -57.277 -56.676 -55.359 -53.96  -54.5...  ...   \n",
       "9  [-60.    -60.    -29.164 ... -36.785 -21.096 -...  ...   \n",
       "\n",
       "  metadata/songs/artist_id metadata/songs/artist_latitude  \\\n",
       "0       ARD7TVE1187B99BFB1                            NaN   \n",
       "1       ARMJAGH1187FB546F3                       35.14968   \n",
       "2       ARKRRTF1187B9984DA                            NaN   \n",
       "3       AR7G5I41187FB4CE6C                            NaN   \n",
       "4       ARXR32B1187FB57099                            NaN   \n",
       "5       ARKFYS91187B98E58F                            NaN   \n",
       "6       ARD0S291187B9B7BF5                            NaN   \n",
       "7       AR10USD1187B99F3F1                            NaN   \n",
       "8       AR8ZCNI1187B9A069B                            NaN   \n",
       "9       ARNTLGG11E2835DDB9                            NaN   \n",
       "\n",
       "  metadata/songs/artist_location  metadata/songs/artist_longitude  \\\n",
       "0                California - LA                              NaN   \n",
       "1                    Memphis, TN                        -90.04892   \n",
       "2                            NaN                              NaN   \n",
       "3                London, England                              NaN   \n",
       "4                            NaN                              NaN   \n",
       "5                            NaN                              NaN   \n",
       "6                           Ohio                              NaN   \n",
       "7    Burlington, Ontario, Canada                              NaN   \n",
       "8                            NaN                              NaN   \n",
       "9                            NaN                              NaN   \n",
       "\n",
       "             metadata/songs/artist_mbid  metadata/songs/artist_name  \\\n",
       "0  e77e51a5-4761-45b3-9847-2051f811e366                      Casual   \n",
       "1  1c78ab62-db33-4433-8d0b-7c8dcf1849c2                The Box Tops   \n",
       "2  7a273984-edd9-4451-9c4d-39b38f05ebcd            Sonora Santanera   \n",
       "3  e188a520-9cb7-4f73-a3d7-2f70c6538e92                    Adam Ant   \n",
       "4  c6903a2e-063c-4f91-a284-17b8f421be7b                         Gob   \n",
       "5  79c403f9-5467-4f23-8426-9ca3fc60a115       Jeff And Sheri Easter   \n",
       "6  56503d6d-094e-4c28-ae3d-04cc748ade5b                     Rated R   \n",
       "7  d89de379-665d-425c-b2e9-41b95d1edb36       Tweeterfriendly Music   \n",
       "8  19d232b9-b4d7-4dc8-b259-bf65efb655b1            Planet P Project   \n",
       "9  4d96f7d0-2f0e-4e92-ba70-a405f96f8cec                         Clp   \n",
       "\n",
       "       musicbrainz/artist_mbtags  musicbrainz/artist_mbtags_count  \\\n",
       "0                             []                               []   \n",
       "1      [b'classic pop and rock']                              [1]   \n",
       "2                             []                               []   \n",
       "3  [b'uk' b'british' b'english']                          [1 1 1]   \n",
       "4                             []                               []   \n",
       "5                             []                               []   \n",
       "6                             []                               []   \n",
       "7                             []                               []   \n",
       "8                             []                               []   \n",
       "9                             []                               []   \n",
       "\n",
       "   musicbrainz/songs/idx_artist_mbtags  musicbrainz/songs/year  \n",
       "0                                    0                       0  \n",
       "1                                    0                    1969  \n",
       "2                                    0                       0  \n",
       "3                                    0                    1982  \n",
       "4                                    0                    2007  \n",
       "5                                    0                       0  \n",
       "6                                    0                       0  \n",
       "7                                    0                       0  \n",
       "8                                    0                    1984  \n",
       "9                                    0                       0  \n",
       "\n",
       "[10 rows x 74 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN !!ONLY!! THIS (AND NOT THE CELL ABOVE) IF songs.csv ALREADY EXISTS IN YOUR data/ folder\n",
    "df = pd.read_csv(\"data/songs.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: bars_confidence, bars_start, beats_confidence, beats_start, sections_confidence, sections_start, segments_confidence, segments_loudness_max, segments_loudness_max_time, segments_loudness_start, segments_pitches, segments_start, segments_timbre, songs, tatums_confidence, tatums_start, artist_terms, artist_terms_freq, artist_terms_weight, similar_artists, songs, artist_mbtags, artist_mbtags_count, songs\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "file_path = \"data/TRAXLZU12903D05F94.h5\"  # Ensure correct file path\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    with h5py.File(file_path, \"r\") as h5_file:\n",
    "        def find_genre(group):\n",
    "            \"\"\" Look for a dataset related to song genre and print it \"\"\"\n",
    "            for key in group.keys():\n",
    "                item = group[key]\n",
    "                if \"songs\" in key.lower() and isinstance(item, h5py.Dataset):  # Filter for genre dataset\n",
    "                    print(f\"Song Genre | Shape: {item.shape} | Type: {item.dtype} | Sample: {item[:5]}\")\n",
    "                elif isinstance(item, h5py.Group):\n",
    "                    find_genre(item)  # Recursive search for nested groups\n",
    "\n",
    "        find_genre(h5_file)\n",
    "else:\n",
    "    print(f\"File not found at: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Taste Profile Subset\n",
    "\n",
    "In order to create vector embeddings for our tracks, we will have to first transform the taste profile subset such that it contains the top 5 tracks of each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Taste Profile subset\n",
    "temp_df = pd.read_csv(\n",
    "    \"data/train_triplets.txt\",\n",
    "    delimiter=\"\\t\",\n",
    "    names=[\"user_id\", \"song_id\", \"play_count\"],\n",
    ")\n",
    "temp_df = temp_df.sort_values(by=[\"user_id\", \"play_count\"], ascending=[True, False])\n",
    "\n",
    "# Only use a subset of the data\n",
    "temp_df = temp_df.head(math.floor(len(temp_df.index) * 0.25))\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use a subset of the data\n",
    "temp_df = temp_df.head(math.floor(len(temp_df.index) * 0.01))\n",
    "temp_df.head()\n",
    "\n",
    "# Assign an index to every unique song in the list\n",
    "codes, unique = pd.factorize(temp_df[\"song_id\"])\n",
    "temp_df[\"song_id_coded\"] = pd.to_numeric(codes)\n",
    "\n",
    "# Get some useful stats\n",
    "num_songs = len(unique)\n",
    "num_users = len(temp_df[\"user_id\"].value_counts().keys())\n",
    "\n",
    "# Find top 5 songs\n",
    "limit = 5\n",
    "\n",
    "track_cols = [f\"track_{i}_coded\" for i in range(1, limit + 1)]\n",
    "top_songs = temp_df.groupby(\"user_id\").head(limit)\n",
    "taste_profile_df = (\n",
    "    top_songs.groupby(\"user_id\")[\"song_id_coded\"].apply(list).reset_index()\n",
    ")\n",
    "taste_profile_df.columns = [\"user\", f\"top_{limit}_song_id_coded\"]\n",
    "taste_profile_df[[f\"track_{i}_coded\" for i in range(1, limit + 1)]] = pd.DataFrame(\n",
    "    taste_profile_df[f\"top_{limit}_song_id_coded\"].to_list(), index=taste_profile_df.index\n",
    ")\n",
    "\n",
    "print(f\"There are {num_songs} songs and {num_users} users in our selection.\")\n",
    "\n",
    "taste_profile_df.to_csv(\"data/taste_profile.csv\", index=False)\n",
    "taste_profile_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some basics in pandas and numpy\n",
    "\n",
    "Reshaping matrices or arrays allows you to modify its dimensions.\n",
    "\n",
    "If you need to produce a dataframe with only one feature then the best way to do it is `df[[\"feature\"]]`. You can also use the same method to generate a dataframe with a subset of its original columns. Simply enter the columns you wish to select in the list like `df[[\"feature_1\", \"feature_2\"]]`. The numpy equivalent of this is `np.reshape(df, (-1, 1))`. However, the disadvantage of using numpy is that the feature's names are not preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/tempo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/loudness\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key\n",
    "The key of the song where 0 represents C, 1 represents D and so on.\n",
    "\n",
    "[Ref.](https://stackoverflow.com/questions/32202589/pyechonest-how-to-interpret-key-and-mode-attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode\n",
    "Indicates if the track is in the major key or minor key. In other words, a track is said to be in C Major if its key is 0 and its mode is 1.\n",
    "\n",
    "[Ref.](https://stackoverflow.com/questions/32202589/pyechonest-how-to-interpret-key-and-mode-attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/mode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/time_signature\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding\n",
    "As it currently stands, some categorical features exist in numerical formats which can cause the model to infer incorrect relationships. Taking key as an example, the model should not assume that there is some kind of increasing relationship from one key to the next but rather treat each key individually as separate features. Making multiple features for each key can be computationally expensive which is why we opt to create one-hot-encodings instead.\n",
    "\n",
    "[Learn more](https://developers.google.com/machine-learning/crash-course/categorical-data/one-hot-encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoding vectors\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoder.set_output(transform=\"pandas\")\n",
    "\n",
    "df_encoded_keys = encoder.fit_transform(df[[\"analysis/songs/key\"]])\n",
    "df_encoded_mode = encoder.fit_transform(df[[\"analysis/songs/mode\"]])\n",
    "\n",
    "df = pd.concat([df, df_encoded_keys, df_encoded_mode], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Some features need to be normalized to a common range to improve the model. Most features with an even distribution will be normalized using the Standard Scaler (Z-score distribution).\n",
    "\n",
    "[Learn more](https://developers.google.com/machine-learning/crash-course/numerical-data/normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the StandardScaler to normalize datapoints in the tempo column using Z-score distribution\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df[\"analysis/songs/tempo\"] = scaler.fit_transform(df[[\"analysis/songs/tempo\"]])\n",
    "df[\"analysis/songs/loudness\"] = scaler.fit_transform(df[[\"analysis/songs/loudness\"]])\n",
    "df[\"analysis/songs/duration\"] = scaler.fit_transform(df[[\"analysis/songs/duration\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/tempo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/loudness\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"analysis/songs/duration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Network\n",
    "\n",
    "In order to make good predictions of what a user might listen to, we ought to select the most appropriate model for the task. The best way to approach this problem would be to create embeddings for each song in the taste profile subset. To do this, we can select the top 5 songs of each user and then use the top 4 songs as features to predict the 5th song. This allows us to approach the problem as a supervised classification problem. By handling it this way, the model can learn latent features for each song as it tries to understand the relationship between the top 5 songs for each individual user. When we make the 5th song the objective of the learning, the model will try to create embeddings the first four songs and tries to understand their relationship. This should in theory correctly place similar songs closer together in the embedding space. The final output of the model would be a vector of probabilities representing the user's odds to interact with each item.\n",
    "\n",
    "There are over 300,000 songs when you consider the whole dataset. This would be too large to represent using one-hot encodings since this would create very sparse input vectors of the order of 300,000 times the number of users. Instead, it would be more appropriate to give each song a label and allow the model to create lower dimensional embeddings to represent each song.\n",
    "\n",
    "[Ref.](https://discuss.pytorch.org/t/what-kind-of-loss-is-better-to-use-in-multilabel-classification/32203/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating targets\n",
    "\n",
    "There are two ways of defining our model's objective. One method is to train the model to predict exactly the 5th song while the other alternative is to ensure that it predicts the correct odds of the user interacting with not only the 5th song but also the original 4. For this reason, we have two variants of the target - one being a one hot encoding of the 5th track and the other a multi hot encoding of all 5 tracks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating target tensors for training the model\n",
    "# Single-label targets where we try to predict the last track in the user's list of top n tracks\n",
    "target_s = F.one_hot(\n",
    "    torch.tensor(taste_profile_df[f\"track_{len(track_cols)}_coded\"].to_numpy()),\n",
    "    num_classes=num_songs,\n",
    ").type(torch.float32)\n",
    "\n",
    "# Multi-label targets where we try to predict all of the user's top n tracks\n",
    "tracks = torch.tensor(taste_profile_df[track_cols].to_numpy())\n",
    "\n",
    "# Creates a matrix filled with zeroes of the size (num_users x num_songs),\n",
    "# then fills it in with 1s based on the indices given in tracks.\n",
    "# THIS WILL ONLY WORK CORRECTLY IF THE SONGS ARE ENCODED STRICTLY FROM 0 TO num_songs - 1\n",
    "target_m = torch.zeros(num_users, num_songs).scatter_(1, tracks, 1.0)\n",
    "\n",
    "model_input = torch.tensor(taste_profile_df[track_cols[:-1]].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passes = 0\n",
    "num_tests = 10000\n",
    "for idx in range(num_tests):\n",
    "    # Select a random user and a random song\n",
    "    x = randint(0, num_users - 1)\n",
    "    y = randint(0, num_songs - 1)\n",
    "    z = randint(1, len(track_cols))\n",
    "\n",
    "    # Expect 1 if the randomly selected user has the randomy selected song in their top 5\n",
    "    expected_s = (\n",
    "        1 if taste_profile_df.iloc[x][f\"track_{len(track_cols)}_coded\"] == y else 0\n",
    "    )\n",
    "    # At the same time, find out what song the randomly selected user actually likes\n",
    "    song_id_s = taste_profile_df.iloc[x][f\"track_{len(track_cols)}_coded\"]\n",
    "    song_id_m = taste_profile_df.iloc[x][f\"track_{z}_coded\"]\n",
    "\n",
    "    cond_expected_s = (\n",
    "        target_s[x][y].item() == expected_s and target_s[x][song_id_s].item() == 1\n",
    "    )\n",
    "    cond_expected_m = target_m[x][song_id_m].item() == 1\n",
    "\n",
    "    if cond_expected_s:\n",
    "        passes += 1\n",
    "\n",
    "print(f\"{passes} of {num_tests} tests passed.\")\n",
    "if passes < num_tests:\n",
    "    print(\"Do not proceed with training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    torch.accelerator.current_accelerator().type\n",
    "    if torch.accelerator.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_len = 4   # The number of favourite songs considered as input for each user\n",
    "embedding_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationModel(nn.Module):\n",
    "    def __init__(self, num_songs, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_songs, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, 12)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(12, 12)\n",
    "        self.fc3 = nn.Linear(12, num_songs)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        # x = x.mean(dim=1)\n",
    "        x = x.max(dim=1)[0]\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = RecommendationModel(num_songs, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ddee932ab0>]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "batch_size = 10\n",
    "loss_vals = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(model_input), batch_size):\n",
    "        batch = model_input[i:i + batch_size]\n",
    "        y_pred = model(batch)\n",
    "        y_batch = target_m[i: i + batch_size]\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    loss_vals.append(loss.item())\n",
    "\n",
    "plt.plot([e + 1 for e in range(n_epochs)], loss_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter 4 songs as input. They must be encoded between 0 and num_songs - 1\n",
    "profile = [56, 57, 59, 58]\n",
    "logits = model(torch.tensor([profile]))\n",
    "probabilities = F.softmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[0.1811, 0.1381, 0.1165, 0.0392, 0.0388, 0.0382, 0.0369, 0.0327, 0.0181,\n",
       "         0.0160]], grad_fn=<TopkBackward0>),\n",
       "indices=tensor([[   56,    57,    58,  8964,  8969, 41632, 23219, 41633,  7986, 42481]]))"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the top 5 songs that the user is likely to interact with.\n",
    "torch.topk(probabilities, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
